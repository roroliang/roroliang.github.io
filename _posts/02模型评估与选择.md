# 02模型评估与选择

## 2.1经验误差与过拟合

- 误差：样本真实输出与预测输出之间的差异，如分类错误率，回归误差
- 经验误差：在训练集上的误差，也叫‘训练误差’
- 泛化误差：在未来样本上的误差，除训练集外的所有样本

根据大数定律，经验误差会收敛于泛化误差，两者（在一定容忍下）相近是由hoeffding不等式作为理论保证的，两者相差过大说明模型的欠拟合或者过拟合，而学习的一致收敛性说的正是这一特性：当训练集足够大，两者的结果就会足够相近，这样我们通过样本的“管中窥豹”的目的才能达到，最终才能获得一个目标假设。

- 过拟合：学习器把训练样本本身特点当做所有潜在样本都会具有的一般性质
- 欠拟合：训练样本的一般性质尚未被学习器学好

----

过拟合：

- 学习器把训练样本学习的“太好”，将训练样本本身的特点当做所有样本的一般性质，导致泛化性能下降
- 优化目标加正则项
- Early Stop
- 过拟合只能缓解，无法彻底避免

欠拟合：

- 对训练样本的一般性质尚未学好
- 决策树:拓展分支
- 神经网络:增加训练轮数

## 2.3性能度量

### 性能度量

- 性能度量是衡量模型泛化能力的评价标准，反映了任务需求； 使用不同的性能度量往往会导致不同的评判结果
- 在预测任务中，给定样例集$D={\{(x1,y1),(x2,y2),(x_m,y_m)}\}$评估学习器的性能 f也即把预测结果$f(x)$ 和真实标记比较.

- 回归任务最常用的性能度量是“均方误差”

$$
E(f;D)=\frac{1}{m}\sum_{i=1}^{m}({f(x_i)-y_i})^2
$$

### 错误率

- 分错样本占样本总数的比例
  $$
  E(f;D)=\frac{1}{m}\sum_{i=1}^{m}\prod({f(x_i)\neq y_i})
  $$
  

### 精度

- 分对样本占样本总数的比率
  $$
  acc(f;D)=\frac{1}{m}\sum_{i=1}^{m}\prod({f(x_i)= y_i})\\=1-E(f;D)
  $$
  

### 混淆矩阵

$$
\begin{array}{||r|r|}
	\hline 真实情况\\
	\hline\\
	\hline\\
	\hline
\end{array}
$$

